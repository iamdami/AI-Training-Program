22-02-07
===
## Normalization
- 값 범위(scale)를 0~1 사이의 값으로 바꿈
- 학습 전에 scaling
  - 머신러닝에서 scale이 큰 feature의 영향 비대해지는 것 방지
  - 딥러닝에서 Local Minima에 빠질 위험 감소(학습 속도 향상)
- scikit-learn : ```MinMaxScaler```
<br>

## Standardization
- 값의 범위(scale)를 평균 0, 분산 1이 되도록 변환
- 학습 전에 scaling
  - 머신러닝에서 scale이 큰 feature의 영향이 비대해지는 것 방지
  - 딥러닝에서 Local Minima에 빠질 위험 감소(학습 속도 향상)
- 정규분포를 표준정규분포로 변환하는 것과 같음
  - Z-score(표준 점수)
  - -1 ~ 1 사이에 68%가 있고, -2 ~ 2 사이에 95%가 있고, -3 ~ 3 사이에 99%가 있음
  - -3 ~ 3의 범위를 벗어나면 outlier일 확률 높음
- 표준화로 번역하기도 함
- scikit-learn에서 ```StandardScaler```
<br>

## Regularization
- weight 조정하는데 제약 거는 기법  
- Overfitting 막기 위해 사용
- L1 regularization, L2 regularizaion 등의 종류 있음
  - L1: LASSO, 마름모
  - L2: Lidge, 원
